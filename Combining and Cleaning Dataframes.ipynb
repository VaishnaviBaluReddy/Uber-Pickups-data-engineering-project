{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e9178de-0a5c-4471-adc5-49168a583d21",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python interpreter will be restarted.\nCollecting geopy\n  Using cached geopy-2.4.1-py3-none-any.whl (125 kB)\nCollecting geographiclib<3,>=1.52\n  Using cached geographiclib-2.0-py3-none-any.whl (40 kB)\nInstalling collected packages: geographiclib, geopy\nSuccessfully installed geographiclib-2.0 geopy-2.4.1\nPython interpreter will be restarted.\n"
     ]
    }
   ],
   "source": [
    "pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ad9ce24-925b-45e1-874f-ec4b2d9e4e38",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import DataFrame\n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import col, sum\n",
    "import geopy as Photon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "97731def-c813-4139-b40e-f3deeb74d5c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[5]: False"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[9]: 18"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of rows '100':\nDataFrame for table 'other_American_B01362':\n+----------+-----------+--------------------+--------------------+\n|      DATE|       Time|     PICK_UP_ADDRESS|            Category|\n+----------+-----------+--------------------+--------------------+\n|07-01-2014|12:00:00 AM| 874 E 139th St M...|other_American_B0...|\n|07-01-2014|12:01:00 AM| 628 E 141st St M...|other_American_B0...|\n+----------+-----------+--------------------+--------------------+\nonly showing top 2 rows\n\nNo of rows '100':\nDataFrame for table 'other_Diplo_B01196':\n+----------+-----------+--------------------+------------------+\n|      Date|       Time|          PU_Address|          Category|\n+----------+-----------+--------------------+------------------+\n|07-01-2014|12:00:00 AM| 2396 Valentine A...|other_Diplo_B01196|\n|07-01-2014|12:01:00 AM| 1859 Walton Ave ...|other_Diplo_B01196|\n+----------+-----------+--------------------+------------------+\nonly showing top 2 rows\n\nNo of rows '100':\nDataFrame for table 'Uber_Jan_Feb_FOIL':\n+-----------------------+----------+---------------+-----+-----------------+\n|dispatching_base_number|      date|active_vehicles|trips|         Category|\n+-----------------------+----------+---------------+-----+-----------------+\n|                 B02512|01-01-2015|            190| 1132|Uber_Jan_Feb_FOIL|\n|                 B02765|01-01-2015|            225| 1765|Uber_Jan_Feb_FOIL|\n+-----------------------+----------+---------------+-----+-----------------+\nonly showing top 2 rows\n\nNo of rows '100':\nDataFrame for table 'other_Firstclass_B01536':\n+----------+-----------+--------------------+--------------------+\n|      DATE|       Time|     PICK_UP_ADDRESS|            Category|\n+----------+-----------+--------------------+--------------------+\n|07-01-2014|12:02:00 AM| 5360 Broadway Ki...|other_Firstclass_...|\n|07-01-2014|12:02:00 AM|    546 Isham St NYC|other_Firstclass_...|\n+----------+-----------+--------------------+--------------------+\nonly showing top 2 rows\n\nNo of rows '100':\nDataFrame for table 'uber_raw_data_janjune_15':\n+--------------------+----------------+-------------------+----------+--------------------+\n|Dispatching_base_num|     Pickup_date|Affiliated_base_num|locationID|            Category|\n+--------------------+----------------+-------------------+----------+--------------------+\n|              B02617|17-05-2015 09:47|             B02617|       141|uber_raw_data_jan...|\n|              B02617|17-05-2015 09:47|             B02617|        65|uber_raw_data_jan...|\n+--------------------+----------------+-------------------+----------+--------------------+\nonly showing top 2 rows\n\nNo of rows '100':\nDataFrame for table 'other_Skyline_B00111':\n+----------+-------------------+--------------+----------+--------------------+\n|      Date|               Time|Street_Address|City_State|            Category|\n+----------+-------------------+--------------+----------+--------------------+\n|07-01-2014|2024-06-03 20:27:00|  622 THIRD AV|      M   |other_Skyline_B00111|\n|07-01-2014|2024-06-03 21:04:00|   E 77TH ST  |      M   |other_Skyline_B00111|\n+----------+-------------------+--------------+----------+--------------------+\nonly showing top 2 rows\n\nNo of rows '100':\nDataFrame for table 'uber_raw_data_apr14':\n+----------------+-------+--------+------+-------------------+\n|       Date/Time|    Lat|     Lon|  Base|           Category|\n+----------------+-------+--------+------+-------------------+\n|04-01-2014 00:11| 40.769|-73.9549|B02512|uber_raw_data_apr14|\n|04-01-2014 00:17|40.7267|-74.0345|B02512|uber_raw_data_apr14|\n+----------------+-------+--------+------+-------------------+\nonly showing top 2 rows\n\nNo of rows '100':\nDataFrame for table 'other_Highclass_B01717':\n+----------+-----------+--------------------+--------------------+\n|      DATE|       Time|          PU_Address|            Category|\n+----------+-----------+--------------------+--------------------+\n|07-01-2014|12:00:00 AM| 2976 Marion Ave ...|other_Highclass_B...|\n|07-01-2014|12:01:00 AM| 780 Grand Concou...|other_Highclass_B...|\n+----------+-----------+--------------------+--------------------+\nonly showing top 2 rows\n\nNo of rows '100':\nDataFrame for table 'other_FHV_services_jan_aug_2015':\n+-----------+-------------------+------------+---------------+------------------+--------------------+\n|Base_Number|          Base_Name|Pick_Up_Date|Number_of_Trips|Number_of_Vehicles|            Category|\n+-----------+-------------------+------------+---------------+------------------+--------------------+\n|     B00013|  LOVE CORP CAR INC|  01-01-2015|             26|                17|other_FHV_service...|\n|     B00014|NY ONE CORP CAR INC|  01-01-2015|             45|                24|other_FHV_service...|\n+-----------+-------------------+------------+---------------+------------------+--------------------+\nonly showing top 2 rows\n\nNo of rows '100':\nDataFrame for table 'uber_raw_data_sep14':\n+----------------+-------+--------+------+-------------------+\n|       Date/Time|    Lat|     Lon|  Base|           Category|\n+----------------+-------+--------+------+-------------------+\n|09-01-2014 00:01|40.2201|-74.0021|B02512|uber_raw_data_sep14|\n|09-01-2014 00:01|  40.75|-74.0027|B02512|uber_raw_data_sep14|\n+----------------+-------+--------+------+-------------------+\nonly showing top 2 rows\n\nNo of rows '100':\nDataFrame for table 'uber_raw_data_jul14':\n+----------------+-------+--------+------+-------------------+\n|       Date/Time|    Lat|     Lon|  Base|           Category|\n+----------------+-------+--------+------+-------------------+\n|07-01-2014 00:03|40.7586|-73.9706|B02512|uber_raw_data_jul14|\n|07-01-2014 00:05|40.7605|-73.9994|B02512|uber_raw_data_jul14|\n+----------------+-------+--------+------+-------------------+\nonly showing top 2 rows\n\nNo of rows '100':\nDataFrame for table 'other_Federal_02216':\n+----------+-------+--------------------+--------------------+--------------------+--------------------+---------+-------------------+\n|      Date|   Time|         PU_Address2|          DO_Address|     Routing_Details|         PU_Address5|   Status|           Category|\n+----------+-------+--------------------+--------------------+--------------------+--------------------+---------+-------------------+\n|07-01-2014|7:15 AM|Brooklyn Museum, ...|1 Brookdale Plaza...|PU: Brooklyn Muse...|Brooklyn Museum, ...|Cancelled|other_Federal_02216|\n|07-01-2014|7:30 AM|33 Robert Dr., Sh...|John F Kennedy In...|PU: 33 Robert Dr....|33 Robert Dr., Sh...|  Arrived|other_Federal_02216|\n+----------+-------+--------------------+--------------------+--------------------+--------------------+---------+-------------------+\nonly showing top 2 rows\n\nNo of rows '100':\nDataFrame for table 'uber_raw_data_aug14':\n+----------------+-------+--------+------+-------------------+\n|       Date/Time|    Lat|     Lon|  Base|           Category|\n+----------------+-------+--------+------+-------------------+\n|08-01-2014 00:03|40.7366|-73.9906|B02512|uber_raw_data_aug14|\n|08-01-2014 00:09| 40.726|-73.9918|B02512|uber_raw_data_aug14|\n+----------------+-------+--------+------+-------------------+\nonly showing top 2 rows\n\nNo of rows '100':\nDataFrame for table 'uber_raw_data_may14':\n+----------------+-------+--------+------+-------------------+\n|       Date/Time|    Lat|     Lon|  Base|           Category|\n+----------------+-------+--------+------+-------------------+\n|05-01-2014 00:02|40.7521|-73.9914|B02512|uber_raw_data_may14|\n|05-01-2014 00:06|40.6965|-73.9715|B02512|uber_raw_data_may14|\n+----------------+-------+--------+------+-------------------+\nonly showing top 2 rows\n\nNo of rows '100':\nDataFrame for table 'uber_raw_data_jun14':\n+----------------+-------+--------+------+-------------------+\n|       Date/Time|    Lat|     Lon|  Base|           Category|\n+----------------+-------+--------+------+-------------------+\n|06-01-2014 00:00|40.7293| -73.992|B02512|uber_raw_data_jun14|\n|06-01-2014 00:01|40.7131|-74.0097|B02512|uber_raw_data_jun14|\n+----------------+-------+--------+------+-------------------+\nonly showing top 2 rows\n\nNo of rows '100':\nDataFrame for table 'other_Lyft_B02510':\n+----------------+---------+---------+-----------------+\n|    time_of_trip|start_lat|start_lng|         Category|\n+----------------+---------+---------+-----------------+\n|09-04-2014 09:51| 40.64705|-73.77988|other_Lyft_B02510|\n| 8/27/2014 21:13| 40.74916|-73.98373|other_Lyft_B02510|\n+----------------+---------+---------+-----------------+\nonly showing top 2 rows\n\nNo of rows '100':\nDataFrame for table 'other_Prestige_B01338':\n+----------+-----------+--------------------+--------------------+\n|      DATE|       Time|     PICK_UP_ADDRESS|            Category|\n+----------+-----------+--------------------+--------------------+\n|07-01-2014|12:00:00 AM| 2557 Marion Ave ...|other_Prestige_B0...|\n|07-01-2014|12:00:00 AM| 45 E Mosholu Pkw...|other_Prestige_B0...|\n+----------+-----------+--------------------+--------------------+\nonly showing top 2 rows\n\nNo of rows '100':\nDataFrame for table 'other_Carmel_B00256':\n+----------+-------------------+---------------+-------+-------------------+\n|      Date|               Time|      PU_Adress|Base_No|           Category|\n+----------+-------------------+---------------+-------+-------------------+\n|07-01-2014|2024-06-03 00:00:00|260 W 44 St NYC| B00256|other_Carmel_B00256|\n|07-01-2014|2024-06-03 00:00:00|125 W 29 St Nyc| B00256|other_Carmel_B00256|\n+----------+-------------------+---------------+-------+-------------------+\nonly showing top 2 rows\n\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[11]: DataFrame[key: string, value: string]"
     ]
    }
   ],
   "source": [
    "%run \"/Users/vaishnavi.balureddy2@cognizant.com/Uber Pick Ups/Formatting Silver Dataframes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc759756-d468-4c40-a78b-51acb548b144",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[37]: DataFrame[key: string, value: string]"
     ]
    }
   ],
   "source": [
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d30fd7ef-c260-42ca-97dd-27042799aadf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema1 = StructType([\n",
    "    StructField(\"Date\", StringType(), True),\n",
    "    StructField(\"Time\", StringType(), True),\n",
    "    StructField(\"Lat\", DoubleType(), True),\n",
    "    StructField(\"Lon\", DoubleType(), True),\n",
    "    StructField(\"Dispatching_Base_Num\", StringType(), True),\n",
    "    StructField(\"Category\", StringType(), True),\n",
    "])\n",
    "\n",
    "\n",
    "schema2 = StructType([\n",
    "    StructField(\"Date\", StringType(), True),\n",
    "    StructField(\"Dispatching_Base_Num\", StringType(), True),\n",
    "    StructField(\"Category\", StringType(), True),\n",
    "    StructField(\"Active_Vehicles\", IntegerType(), True),\n",
    "    StructField(\"Base_Name\", StringType(), True),\n",
    "    StructField(\"Trips\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "schema3 = StructType([\n",
    "    StructField(\"Date\", StringType(), True),\n",
    "    StructField(\"Time\", StringType(), True),\n",
    "    StructField(\"Pickup_Address\", StringType(), True),\n",
    "    StructField(\"Category\", StringType(), True)\n",
    "])\n",
    "\n",
    "schema4 = StructType([\n",
    "    StructField(\"Date\", StringType(), True),\n",
    "    StructField(\"Time\", StringType(), True),\n",
    "    StructField(\"Dispatching_Base_Num\", StringType(), True),\n",
    "    StructField(\"Category\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc3feb86-ea56-452a-b15a-3bc40068d13f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dfs1 = {\n",
    "    \"uber_raw_data_apr14\": dfs[\"uber_raw_data_apr14\"],\n",
    "    \"uber_raw_data_may14\": dfs[\"uber_raw_data_may14\"],\n",
    "    \"uber_raw_data_jun14\": dfs[\"uber_raw_data_jun14\"],\n",
    "    \"uber_raw_data_jul14\": dfs[\"uber_raw_data_jul14\"],\n",
    "    \"uber_raw_data_aug14\": dfs[\"uber_raw_data_aug14\"],\n",
    "    \"uber_raw_data_sep14\": dfs[\"uber_raw_data_sep14\"]\n",
    "}\n",
    "\n",
    "dfs2 = {\n",
    "    \"Uber_Jan_Feb_FOIL\": dfs[\"Uber_Jan_Feb_FOIL\"],\n",
    "    \"other_FHV_services_jan_aug_2015\": dfs[\"other_FHV_services_jan_aug_2015\"]\n",
    "}\n",
    "\n",
    "dfs3 = {\n",
    "    \"other_Skyline_B00111\": dfs[\"other_Skyline_B00111\"],\n",
    "    \"other_Firstclass_B01536\": dfs[\"other_Firstclass_B01536\"],\n",
    "    \"other_American_B01362\": dfs[\"other_American_B01362\"],\n",
    "    \"other_Highclass_B01717\": dfs[\"other_Highclass_B01717\"],\n",
    "    \"other_Prestige_B01338\": dfs[\"other_Prestige_B01338\"],\n",
    "    \"other_Federal_02216\": dfs[\"other_Federal_02216\"], \n",
    "    \"other_Carmel_B00256\": dfs[\"other_Carmel_B00256\"],\n",
    "    \"other_Lyft_B02510\": dfs[\"other_Lyft_B02510\"]\n",
    "}\n",
    "\n",
    "dfs4 = {\n",
    "    \"uber_raw_data_janjune_15\": dfs[\"uber_raw_data_janjune_15\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9969a253-b6f8-4f22-8d5b-7097808e29a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "combined_df = spark.createDataFrame([], schema=schema1)\n",
    "\n",
    "for table_name, df in dfs1.items():\n",
    "\n",
    "    try:\n",
    "        combined_df = combined_df.unionByName(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred with DataFrame: {table_name}\")\n",
    "        print(e)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21f28f1a-4b55-4070-ae39-860086258ba1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------+--------------------+-------------------+--------+--------+\n|      Date|    Lat|     Lon|Dispatching_Base_Num|           Category|    Time| trip_ID|\n+----------+-------+--------+--------------------+-------------------+--------+--------+\n|2014-04-01| 40.769|-73.9549|              B02512|uber_raw_data_apr14|00:11:00|11947673|\n|2014-04-01|40.7267|-74.0345|              B02512|uber_raw_data_apr14|00:17:00|11947673|\n|2014-04-01|40.7316|-73.9873|              B02512|uber_raw_data_apr14|00:21:00|11947673|\n|2014-04-01|40.7588|-73.9776|              B02512|uber_raw_data_apr14|00:28:00|11947673|\n|2014-04-01|40.7594|-73.9722|              B02512|uber_raw_data_apr14|00:33:00|11947674|\n+----------+-------+--------+--------------------+-------------------+--------+--------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "Uber_AprSep14 = combined_df.withColumn('timestamp_string',to_timestamp('Time')) \n",
    "Uber_AprSep14 = Uber_AprSep14.withColumn(\"timestamp_string1\", split(\"timestamp_string\", \" \")[1])\n",
    "\n",
    "Uber_AprSep14 = Uber_AprSep14.drop('Time')\n",
    "Uber_AprSep14 = Uber_AprSep14.withColumnRenamed(\"timestamp_string1\", \"Time\")\n",
    "Uber_AprSep14 = Uber_AprSep14.drop('timestamp_string')\n",
    "Uber_AprSep14 = Uber_AprSep14.drop('timestamp_string1')\n",
    "\n",
    "Uber_AprSep14 = Uber_AprSep14.withColumn(\"trip_ID\", concat(lit('1'), lpad((monotonically_increasing_id() % 100000000).cast('string'), 7, '0'))) \n",
    "Uber_AprSep14.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89b28d24-7b0e-4640-951c-b3ac508756e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "all_columns = set([\"Date\",\"Dispatching_Base_Num\",\"Category\",\"Active_Vehicles\",\"Base_Name\",\"Trips\"])\n",
    "combined_df = spark.createDataFrame([], schema=schema2)\n",
    "\n",
    "# Iterate over the existing DataFrames and add columns to the combined DataFrame\n",
    "for table_name, df in dfs2.items():\n",
    "    existing_columns = set(df.columns)\n",
    "    missing_columns = all_columns - existing_columns\n",
    "    \n",
    "    # Add missing columns with null values\n",
    "    for col in missing_columns:\n",
    "        df = df.withColumn(col, lit(\"Uber\"))\n",
    "    #Remove white spaces in column names to resolve columns\n",
    "    tempList = [] \n",
    "    for col in df.columns:\n",
    "        new_name = col.strip()\n",
    "        new_name = \"\".join(new_name.split())\n",
    "        new_name = new_name.replace('.','') \n",
    "        tempList.append(new_name)\n",
    "\n",
    "    try:\n",
    "        combined_df = combined_df.unionByName(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred with DataFrame: {table_name}\")\n",
    "        print(e)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dbf0e5f-b95b-4986-93e6-c7b95a9b22cc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[43]: [Row(Date='01-02-2015', Dispatching_Base_Num='B01777', Category='other_FHV_services_jan_aug_2015', Active_Vehicles='131', Base_Name='PREMIUM RADIO DISP & MULTI SVC', Trips='677', trip_ID='29411423'),\n Row(Date='01-02-2015', Dispatching_Base_Num='B01848', Category='other_FHV_services_jan_aug_2015', Active_Vehicles=' -   ', Base_Name='GRAND LIMO & CAR SERVICE INC.', Trips='11', trip_ID='29411424'),\n Row(Date='01-02-2015', Dispatching_Base_Num='B01877', Category='other_FHV_services_jan_aug_2015', Active_Vehicles='43', Base_Name='U.S.A. LIMO. INC.', Trips='76', trip_ID='29411425'),\n Row(Date='01-02-2015', Dispatching_Base_Num='B01899', Category='other_FHV_services_jan_aug_2015', Active_Vehicles='88', Base_Name='ALLSTATE PRIVATE CAR & LIMO,INC', Trips='726', trip_ID='29411426'),\n Row(Date='01-02-2015', Dispatching_Base_Num='B01949', Category='other_FHV_services_jan_aug_2015', Active_Vehicles='1', Base_Name='FIRST CLASS OF NEW YORK INC.', Trips='1', trip_ID='29411427')]"
     ]
    }
   ],
   "source": [
    "UBERandFHV = combined_df\n",
    "UBERandFHV = UBERandFHV.withColumn(\"trip_ID\", concat(lit('2'), lpad((monotonically_increasing_id() % 100000000).cast('string'), 7, '0')))\n",
    "UBERandFHV.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "782ca71a-6b62-4825-bac7-bc59c0eb4da2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique categories in UBERandFHV:\nB02512\nB02598\nB02682\nB02765\nB02617\nB02764\nB01341\nB00887\nB02715\nB00948\nB01197\nB00029\nB01313\nB01386\nB00381\nB00254\nB00837\nB02003\nB01087\nB00221\nB01300\nB01285\nB02513\nB01367    \nB02569\nB02653\nB02566\nB02022\nB01899\nB01848\nB01083\nB00412\nB01990\nB01282\nB00310\nB02285\nB00013\nB00227\nB00457\nB01312\nB01148\nB01522\nB01066\nB01651\nB00014\nB00053\nB00919\nB02475\nB02147\nB00477\nb01346\nB01777\nB01877\nB02120\nB01315\nB00280\nB02107\nB00552\nB00623\nB00248\nB00095\nB01949\nB02096\nB01984\n+----------+--------------------+-----------------+---------------+---------+-----+--------+\n|      Date|Dispatching_Base_Num|         Category|Active_Vehicles|Base_Name|Trips| trip_ID|\n+----------+--------------------+-----------------+---------------+---------+-----+--------+\n|01-01-2015|              B02512|Uber_Jan_Feb_FOIL|            190|     Uber| 1132|21947673|\n|01-01-2015|              B02765|Uber_Jan_Feb_FOIL|            225|     Uber| 1765|21947673|\n|01-01-2015|              B02764|Uber_Jan_Feb_FOIL|           3427|     Uber|29421|21947673|\n|01-01-2015|              B02682|Uber_Jan_Feb_FOIL|            945|     Uber| 7679|21947673|\n|01-01-2015|              B02617|Uber_Jan_Feb_FOIL|           1228|     Uber| 9537|21947674|\n|01-01-2015|              B02598|Uber_Jan_Feb_FOIL|            870|     Uber| 6903|21947674|\n|01-02-2015|              B02598|Uber_Jan_Feb_FOIL|            785|     Uber| 4768|21947674|\n|01-02-2015|              B02617|Uber_Jan_Feb_FOIL|           1137|     Uber| 7065|21947674|\n|01-02-2015|              B02512|Uber_Jan_Feb_FOIL|            175|     Uber|  875|21947674|\n|01-02-2015|              B02682|Uber_Jan_Feb_FOIL|            890|     Uber| 5506|21947674|\n|01-02-2015|              B02765|Uber_Jan_Feb_FOIL|            196|     Uber| 1001|21947674|\n|01-02-2015|              B02764|Uber_Jan_Feb_FOIL|           3147|     Uber|19974|21947674|\n|01-03-2015|              B02765|Uber_Jan_Feb_FOIL|            201|     Uber| 1526|21947674|\n|01-03-2015|              B02617|Uber_Jan_Feb_FOIL|           1188|     Uber|10664|21947674|\n|01-03-2015|              B02598|Uber_Jan_Feb_FOIL|            818|     Uber| 7432|21947675|\n|01-03-2015|              B02682|Uber_Jan_Feb_FOIL|            915|     Uber| 8010|21947675|\n|01-03-2015|              B02512|Uber_Jan_Feb_FOIL|            173|     Uber| 1088|21947675|\n|01-03-2015|              B02764|Uber_Jan_Feb_FOIL|           3215|     Uber|29729|21947675|\n|01-04-2015|              B02512|Uber_Jan_Feb_FOIL|            147|     Uber|  791|21947675|\n|01-04-2015|              B02682|Uber_Jan_Feb_FOIL|            812|     Uber| 5621|21947675|\n+----------+--------------------+-----------------+---------------+---------+-----+--------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "unique_categories = UBERandFHV.select('Dispatching_Base_Num').distinct().collect()\n",
    "\n",
    "print(\"Unique categories in UBERandFHV:\")\n",
    "for row in unique_categories:\n",
    "    print(row['Dispatching_Base_Num'])\n",
    "UBERandFHV.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c04ddb04-b9cb-49f5-8f93-c261c3a3c92d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "combined_df = spark.createDataFrame([], schema=schema3)\n",
    "\n",
    "for table_name, df in dfs3.items():\n",
    "\n",
    "    try:\n",
    "        combined_df = combined_df.unionByName(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred with DataFrame: {table_name}\")\n",
    "        print(e)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e88a8366-961c-4c9d-a10f-ebd83cf55917",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+--------+--------+\n|      Date|      Pickup_Address|            Category|    Time| trip_ID|\n+----------+--------------------+--------------------+--------+--------+\n|07-01-2014|   622 THIRD AV M   |other_Skyline_B00111|20:27:00|31947673|\n|07-01-2014|    E 77TH ST   M   |other_Skyline_B00111|21:04:00|31947673|\n|07-01-2014|67 WEST PALISADES...|other_Skyline_B00111|22:20:00|31947673|\n|07-01-2014|130 MIDDLE NECK R...|other_Skyline_B00111|12:28:00|31947673|\n|07-01-2014|   36 E 31ST ST M   |other_Skyline_B00111|16:45:00|31947674|\n+----------+--------------------+--------------------+--------+--------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "FHV_Data = combined_df.withColumn('timestamp_string',to_timestamp('Time')) \n",
    "FHV_Data = FHV_Data.withColumn(\"timestamp_string1\", split(\"timestamp_string\", \" \")[1])\n",
    "\n",
    "FHV_Data = FHV_Data.drop('Time')\n",
    "FHV_Data = FHV_Data.withColumnRenamed(\"timestamp_string1\", \"Time\")\n",
    "FHV_Data = FHV_Data.drop('timestamp_string')\n",
    "FHV_Data = FHV_Data.drop('timestamp_string1')\n",
    "\n",
    "FHV_Data = FHV_Data.withColumn(\"trip_ID\", concat(lit('3'), lpad((monotonically_increasing_id() % 100000000).cast('string'), 7, '0')))\n",
    "                \n",
    "FHV_Data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d659c246-0f26-4059-80d0-f5e379c99b89",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct pickup addresses: 641\n"
     ]
    }
   ],
   "source": [
    "distinct_pickup_addresses_count = FHV_Data.select('Pickup_Address').distinct().count()\n",
    "print(\"Number of distinct pickup addresses:\", distinct_pickup_addresses_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0e2657c-d8e4-44b6-a576-a1d6df31a7ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+--------+--------+\n|Dispatching_Base_Num|            Category|      Date|    Time| trip_ID|\n+--------------------+--------------------+----------+--------+--------+\n|              B02617|uber_raw_data_jan...|2015-05-17|09:47:00|40000000|\n|              B02617|uber_raw_data_jan...|2015-05-17|09:47:00|40000001|\n|              B02617|uber_raw_data_jan...|2015-05-17|09:47:00|40000002|\n|              B02617|uber_raw_data_jan...|2015-05-17|09:47:00|40000003|\n|              B02617|uber_raw_data_jan...|2015-05-17|09:47:00|40000004|\n+--------------------+--------------------+----------+--------+--------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "Uber_JanJun15 = dfs['uber_raw_data_janjune_15'].withColumn('timestamp_string',to_timestamp('Time')) \n",
    "Uber_JanJun15 = Uber_JanJun15.withColumn(\"timestamp_string1\", split(\"timestamp_string\", \" \")[1])\n",
    "\n",
    "Uber_JanJun15 = Uber_JanJun15.drop('Time')\n",
    "Uber_JanJun15 = Uber_JanJun15.withColumnRenamed(\"timestamp_string1\", \"Time\")\n",
    "Uber_JanJun15 = Uber_JanJun15.drop('timestamp_string')\n",
    "Uber_JanJun15 = Uber_JanJun15.drop('timestamp_string1')\n",
    "\n",
    "Uber_JanJun15 = Uber_JanJun15.withColumn(\"trip_ID\", concat(lit('4'), lpad((monotonically_increasing_id() % 100000000).cast('string'), 7, '0')))\n",
    "                \n",
    "Uber_JanJun15.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "362e0f52-753c-4690-918d-a2c85ac87ab0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "base_name_mapping = {\n",
    "    'B02512': 'Unter',\n",
    "    'B02598': 'Hinter',\n",
    "    'B02617': 'Weiter',\n",
    "    'B02682': 'Schmecken',\n",
    "    'B02764': 'Danach-NY',\n",
    "    'B02765': 'Grun',\n",
    "    'B02835': 'Dreist',\n",
    "    'B02836': 'Drinnen'\n",
    "}\n",
    "\n",
    "def get_base_name(base_num):\n",
    "    return base_name_mapping.get(base_num, 'Unknown')\n",
    "get_base_name_udf = udf(get_base_name, StringType())\n",
    "\n",
    "\n",
    "\n",
    "Uber_AprSep14 = Uber_AprSep14.withColumn(\"Base_Name\", get_base_name_udf(Uber_AprSep14[\"Dispatching_Base_Num\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a92042a-f66a-4130-96cf-0e02cb16aee5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------+--------------------+-------------------+--------+--------+---------+\n|      Date|    Lat|     Lon|Dispatching_Base_Num|           Category|    Time| trip_ID|Base_Name|\n+----------+-------+--------+--------------------+-------------------+--------+--------+---------+\n|2014-04-01| 40.769|-73.9549|              B02512|uber_raw_data_apr14|00:11:00|11947673|    Unter|\n|2014-04-01|40.7267|-74.0345|              B02512|uber_raw_data_apr14|00:17:00|11947673|    Unter|\n+----------+-------+--------+--------------------+-------------------+--------+--------+---------+\nonly showing top 2 rows\n\n"
     ]
    }
   ],
   "source": [
    "Uber_AprSep14.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cc410f6-b530-4067-aef2-1ace27c778b8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "Uber_JanJun15 = Uber_JanJun15.withColumn(\"Base_Name\", get_base_name_udf(Uber_JanJun15[\"Dispatching_Base_Num\"]))\n",
    "UBERandFHV = UBERandFHV.withColumn(\"Base_Name\", get_base_name_udf(UBERandFHV[\"Dispatching_Base_Num\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7af94876-b127-4ea3-9275-50744a58ce19",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Uber_JanJun15 = Uber_JanJun15.withColumn(\"Price[$]\", (rand() * (100 - 5) + 5).cast(\"double\"))\n",
    "Uber_JanJun15 = Uber_JanJun15.withColumn(\"Price[$]\", format_number(\"Price[$]\", 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aa8012ca-b0b9-4836-b77a-a13ded8066c9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Writing these silver tables to tables in catalog. Run the next cells or the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e0b1af6-e81a-49ae-8ee5-4d76b4b2fd49",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'Silver_Tables' created successfully at path 'dbfs:/FileStore/UberPickUps/Silver_Tables/'.\n"
     ]
    }
   ],
   "source": [
    "new_folder_name = \"Silver_Tables\"\n",
    "new_folder_path = \"dbfs:/FileStore/UberPickUps/\" + new_folder_name + \"/\"\n",
    "dbutils.fs.mkdirs(new_folder_path)\n",
    "\n",
    "try:\n",
    "    dbutils.fs.mkdirs(new_folder_path)\n",
    "    print(f\"Folder '{new_folder_name}' created successfully at path '{new_folder_path}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to create folder '{new_folder_name}' at path '{new_folder_path}'.\")\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f2ac660-c223-47ca-87d1-306c377ad79b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[54]: DataFrame[]"
     ]
    }
   ],
   "source": [
    "create_db_qry=f\"\"\"CREATE DATABASE IF NOT EXISTS Silver\"\"\"\n",
    "spark.sql(create_db_qry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5bcbae21-329d-4d57-b9b0-d75c0fb5229a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "path =  \"dbfs:/FileStore/UberPickUps/Silver_Tables/Uber_AprSep14/\"\n",
    "Uber_AprSep14.write.format(\"delta\").mode(\"overwrite\").option(\"path\",path).save()\n",
    "Uber_AprSep14.write.mode('append').saveAsTable('Silver.Uber_AprSep14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1d3e670-0a36-4288-9412-89e87c2586e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "Uber_JanJun15.write.format(\"delta\").mode(\"overwrite\").option(\"path\", \"dbfs:/FileStore/UberPickUps/Silver_Tables/Uber_JanJun15/\").save()\n",
    "Uber_JanJun15.write.mode('append').saveAsTable('Silver.Uber_JanJun15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8c53755-ffc5-4e0d-bf1a-12a2a407dbce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "UBERandFHV.write.format(\"delta\").mode(\"overwrite\").option(\"path\", \"dbfs:/FileStore/UberPickUps/Silver_Tables/UBERandFHV/\").save()\n",
    "UBERandFHV.write.mode('append').saveAsTable('Silver.UBERandFHV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "527e3f02-0677-4995-9d31-dbe9fef02370",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "FHV_Data.write.format(\"delta\").mode(\"overwrite\").option(\"path\", \"dbfs:/FileStore/UberPickUps/Silver_Tables/FHV_Data/\").save()\n",
    "FHV_Data.write.mode('append').saveAsTable('Silver.FHV_Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d85d3da9-e5f8-4965-967c-bc8fab8dad5f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Combining and Cleaning Dataframes",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
