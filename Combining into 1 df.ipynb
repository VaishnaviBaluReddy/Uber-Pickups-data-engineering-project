{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99c43db6-565d-4da9-bb8b-01445d723c77",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import DataFrame\n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions as F\n",
    "import os\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import col, sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "922775a0-d7fa-4a63-b993-a54778a609e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"/Users/vaishnavi.balureddy2@cognizant.com/Uber Pick Ups/Formatting Silver Dataframes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8dd192fa-0eab-4a47-bc89-f8b4b5bf8b18",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"Date\", StringType(), True),\n",
    "    StructField(\"Time\", StringType(), True),\n",
    "    StructField(\"Lat\", DoubleType(), True),\n",
    "    StructField(\"Lon\", DoubleType(), True),\n",
    "    StructField(\"Dispatching_Base_Num\", StringType(), True),\n",
    "    StructField(\"Category\", StringType(), True),\n",
    "    StructField(\"Pickup_Address\", StringType(), True),\n",
    "    StructField(\"Active_Vehicles\", IntegerType(), True),\n",
    "    StructField(\"Trips\", IntegerType(), True),\n",
    "    StructField(\"Base_Name\", StringType(), True),\n",
    "    StructField(\"Dropoff_Address\", StringType(), True),\n",
    "    StructField(\"Routing_Details\", StringType(), True),\n",
    "    StructField(\"Status\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "383f014d-b587-4dad-b761-845ed1a03bec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "all_columns = set([\n",
    "    \"Date\", \"Time\", \"Lat\", \"Lon\", \"Dispatching_Base_Num\", \"Category\", \n",
    "    \"Pickup_Address\", \"Active_Vehicles\", \"Trips\", \"Base_Name\", \n",
    "    \"Dropoff_Address\", \"Routing_Details\", \"Status\"\n",
    "])\n",
    "\n",
    "combined_df = spark.createDataFrame([], schema=schema)\n",
    "\n",
    "# Iterate over the existing DataFrames and add columns to the combined DataFrame\n",
    "for table_name, df in dfs.items():\n",
    "    existing_columns = set(df.columns)\n",
    "    missing_columns = all_columns - existing_columns\n",
    "    \n",
    "    # Add missing columns with null values\n",
    "    for col in missing_columns:\n",
    "        df = df.withColumn(col, lit(None))\n",
    "    #Remove white spaces in column names to resolve columns\n",
    "    tempList = [] \n",
    "    for col in df.columns:\n",
    "        new_name = col.strip()\n",
    "        new_name = \"\".join(new_name.split())\n",
    "        new_name = new_name.replace('.','') \n",
    "        tempList.append(new_name)\n",
    "\n",
    "    try:\n",
    "        combined_df = combined_df.unionByName(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred with DataFrame: {table_name}\")\n",
    "        print(e)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c51884ee-115f-494d-a764-d58eff4c783b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-------+--------+--------------------+-------------------+--------------+---------------+-----+---------+---------------+---------------+------+\n|      Date| Time|    Lat|     Lon|Dispatching_Base_Num|           Category|Pickup_Address|Active_Vehicles|Trips|Base_Name|Dropoff_Address|Routing_Details|Status|\n+----------+-----+-------+--------+--------------------+-------------------+--------------+---------------+-----+---------+---------------+---------------+------+\n|2014-04-01|00:11| 40.769|-73.9549|              B02512|uber_raw_data_apr14|          null|           null| null|     null|           null|           null|  null|\n|2014-04-01|00:17|40.7267|-74.0345|              B02512|uber_raw_data_apr14|          null|           null| null|     null|           null|           null|  null|\n|2014-04-01|00:21|40.7316|-73.9873|              B02512|uber_raw_data_apr14|          null|           null| null|     null|           null|           null|  null|\n|2014-04-01|00:28|40.7588|-73.9776|              B02512|uber_raw_data_apr14|          null|           null| null|     null|           null|           null|  null|\n|2014-04-01|00:33|40.7594|-73.9722|              B02512|uber_raw_data_apr14|          null|           null| null|     null|           null|           null|  null|\n+----------+-----+-------+--------+--------------------+-------------------+--------------+---------------+-----+---------+---------------+---------------+------+\nonly showing top 5 rows\n\nOut[93]: 1800"
     ]
    }
   ],
   "source": [
    "combined_df.show(5)\n",
    "combined_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ffe86fec-03d6-48ee-9ddb-c0da6a8a9cea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[94]: DataFrame[key: string, value: string]"
     ]
    }
   ],
   "source": [
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0beed80a-1199-4469-976f-a0229afd37c9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+--------+---------+--------------------+--------------------+--------------------+---------------+-----+-----------------+--------------------+--------------------+---------+\n|      Date|       Time|     Lat|      Lon|Dispatching_Base_Num|            Category|      Pickup_Address|Active_Vehicles|Trips|        Base_Name|     Dropoff_Address|     Routing_Details|   Status|\n+----------+-----------+--------+---------+--------------------+--------------------+--------------------+---------------+-----+-----------------+--------------------+--------------------+---------+\n|01-01-2015|       null|    null|     null|              B02512|   Uber_Jan_Feb_FOIL|                null|            190| 1132|             null|                null|                null|     null|\n|07-01-2014|12:00:00 AM|    null|     null|                null|other_American_B0...| 874 E 139th St M...|           null| null|             null|                null|                null|     null|\n|07-01-2014|   00:00:00|    null|     null|              B00256| other_Carmel_B00256|     260 W 44 St NYC|           null| null|             null|                null|                null|     null|\n|07-01-2014|12:00:00 AM|    null|     null|                null|  other_Diplo_B01196| 2396 Valentine A...|           null| null|             null|                null|                null|     null|\n|01-01-2015|       null|    null|     null|              B00013|other_FHV_service...|                null|             17|   26|LOVE CORP CAR INC|                null|                null|     null|\n|07-01-2014|    7:15 AM|    null|     null|                null| other_Federal_02216|Brooklyn Museum, ...|           null| null|             null|1 Brookdale Plaza...|PU: Brooklyn Muse...|Cancelled|\n|07-01-2014|12:02:00 AM|    null|     null|                null|other_Firstclass_...| 5360 Broadway Ki...|           null| null|             null|                null|                null|     null|\n|07-01-2014|12:00:00 AM|    null|     null|                null|other_Highclass_B...| 2976 Marion Ave ...|           null| null|             null|                null|                null|     null|\n|2014-09-04|      09:51|40.64705|-73.77988|                null|   other_Lyft_B02510|                null|           null| null|             null|                null|                null|     null|\n|07-01-2014|12:00:00 AM|    null|     null|                null|other_Prestige_B0...| 2557 Marion Ave ...|           null| null|             null|                null|                null|     null|\n|07-01-2014|   20:27:00|    null|     null|                null|other_Skyline_B00111|   622 THIRD AV M   |           null| null|             null|                null|                null|     null|\n|2014-04-01|      00:11|  40.769| -73.9549|              B02512| uber_raw_data_apr14|                null|           null| null|             null|                null|                null|     null|\n|2014-08-01|      00:03| 40.7366| -73.9906|              B02512| uber_raw_data_aug14|                null|           null| null|             null|                null|                null|     null|\n|2015-05-17|      09:47|    null|     null|              B02617|uber_raw_data_jan...|                null|           null| null|             null|                null|                null|     null|\n|2014-07-01|      00:03| 40.7586| -73.9706|              B02512| uber_raw_data_jul14|                null|           null| null|             null|                null|                null|     null|\n|2014-06-01|      00:00| 40.7293|  -73.992|              B02512| uber_raw_data_jun14|                null|           null| null|             null|                null|                null|     null|\n|2014-05-01|      00:02| 40.7521| -73.9914|              B02512| uber_raw_data_may14|                null|           null| null|             null|                null|                null|     null|\n|2014-09-01|      00:01| 40.2201| -74.0021|              B02512| uber_raw_data_sep14|                null|           null| null|             null|                null|                null|     null|\n+----------+-----------+--------+---------+--------------------+--------------------+--------------------+---------------+-----+-----------------+--------------------+--------------------+---------+\n\nOut[95]: 18"
     ]
    }
   ],
   "source": [
    "#Print the entire DataFrame for each unique value\n",
    "unique_category_df = combined_df.drop_duplicates(subset=['Category'])\n",
    "unique_category_df.show()\n",
    "unique_category_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3c4ea26-6704-4a02-ad18-126331ca219f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------+--------------------+-------------------+--------------+---------------+-----+---------+---------------+---------------+------+--------+\n|      Date|    Lat|     Lon|Dispatching_Base_Num|           Category|Pickup_Address|Active_Vehicles|Trips|Base_Name|Dropoff_Address|Routing_Details|Status|    Time|\n+----------+-------+--------+--------------------+-------------------+--------------+---------------+-----+---------+---------------+---------------+------+--------+\n|2014-04-01| 40.769|-73.9549|              B02512|uber_raw_data_apr14|          null|           null| null|     null|           null|           null|  null|00:11:00|\n|2014-04-01|40.7267|-74.0345|              B02512|uber_raw_data_apr14|          null|           null| null|     null|           null|           null|  null|00:17:00|\n|2014-04-01|40.7316|-73.9873|              B02512|uber_raw_data_apr14|          null|           null| null|     null|           null|           null|  null|00:21:00|\n|2014-04-01|40.7588|-73.9776|              B02512|uber_raw_data_apr14|          null|           null| null|     null|           null|           null|  null|00:28:00|\n|2014-04-01|40.7594|-73.9722|              B02512|uber_raw_data_apr14|          null|           null| null|     null|           null|           null|  null|00:33:00|\n+----------+-------+--------+--------------------+-------------------+--------------+---------------+-----+---------+---------------+---------------+------+--------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "Final = combined_df.withColumn('timestamp_string',to_timestamp('Time')) \n",
    "Final = Final.withColumn(\"timestamp_string1\", split(\"timestamp_string\", \" \")[1])\n",
    "\n",
    "Final = Final.drop('Time')\n",
    "Final = Final.withColumnRenamed(\"timestamp_string1\", \"Time\")\n",
    "Final = Final.drop('timestamp_string')\n",
    "Final = Final.drop('timestamp_string1')\n",
    "                    \n",
    "                  \n",
    "Final.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "4395a7d8-7ed1-4093-9ccf-c547fee311f1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Base_Condition = [(df[\"Dispatching_Base_Num\"] == \"\"),\n",
    "#                   (df[\"Dispatching_Base_Num\"] == \"\"),]\n",
    "# for condition, new_name in Base_Condition:\n",
    "#     Final = Final.withColumn(\"Base_Name\",\n",
    "#                          when(condition, new_name).otherwise(df[\"Base_Name\"]))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Combining into 1 df",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
